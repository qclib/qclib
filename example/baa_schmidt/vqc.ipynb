{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q-research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.providers.aer.backends import AerSimulator\n",
    "from qiskit.aqua import aqua_globals\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.ml.circuit.library import RawFeatureVector\n",
    "sys.path.append('../../')\n",
    "from qclib.machine_learning.baa_feature_vector import BaaFeatureVector\n",
    "from qclib.machine_learning.vqc import VQC\n",
    "from qclib.machine_learning.datasets import digits\n",
    "from qclib.state_preparation.baa_schmidt import initialize as baa_schmidt\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff80e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset load\n",
    "\n",
    "feature_dim = 64\n",
    "sample_total, training_input, test_input, class_labels = digits.load(classes=[1,3],\n",
    "                                                                     training_size=40,\n",
    "                                                                     test_size=10,\n",
    "                                                                     random_seed=seed)\n",
    "for i in training_input:\n",
    "    print(i, len(training_input[i]))\n",
    "print()\n",
    "for i in test_input:\n",
    "    print(i, len(test_input[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2595ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-local parameterized circuit model\n",
    "\n",
    "n_qubits = int(np.ceil(np.log2(feature_dim)))\n",
    "var_form = TwoLocal(n_qubits, ['ry', 'rz'], 'cz', reps=1)\n",
    "var_form.decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQC experiments\n",
    "\n",
    "def ideal_instance():\n",
    "    ideal = AerSimulator()\n",
    "    return QuantumInstance(ideal, shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "\n",
    "def noisy_instance():\n",
    "    jakarta = provider.get_backend(\"ibmq_jakarta\")\n",
    "    noisy = AerSimulator.from_backend(jakarta)\n",
    "    return QuantumInstance(noisy, shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "\n",
    "aqua_globals.random_seed = seed\n",
    "\n",
    "optimizer = SPSA(maxiter=200)\n",
    "\n",
    "training_size = sum([ len(val) for key, val in training_input.items() ] )\n",
    "batch_size = int(training_size * 0.1)\n",
    "print(training_size)\n",
    "print(batch_size)\n",
    "\n",
    "#feature_map = RawFeatureVector(feature_dimension=feature_dim)\n",
    "feature_map = BaaFeatureVector(feature_dimension=feature_dim, \n",
    "                               strategy='brute_force',\n",
    "                               max_fidelity_loss=0.1,\n",
    "                               use_low_rank=True)\n",
    "\n",
    "vqc = VQC(optimizer, feature_map, var_form, training_input, test_input, None, minibatch_size=batch_size)\n",
    "\n",
    "#quantum_instance = noisy_instance()\n",
    "quantum_instance = ideal_instance()\n",
    "\n",
    "acc = []\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "\n",
    "    result = vqc.run(quantum_instance)\n",
    "    acc.append(result[\"testing_accuracy\"])\n",
    "\n",
    "    print(f'Test accuracy: {result[\"testing_accuracy\"]}')\n",
    "\n",
    "print('AVG:', sum(acc) / len(acc))\n",
    "print('STD:', np.std(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of CNOTs, depth, and fidelity\n",
    "\n",
    "def _fidelity(input_state, transpiled_circuit):\n",
    "    backend = AerSimulator()\n",
    "    transpiled_circuit.save_statevector()\n",
    "    ket = backend.run(transpiled_circuit).result().get_statevector()\n",
    "    bra = np.conj(input_state)\n",
    "\n",
    "    return np.abs(bra.dot(ket))**2\n",
    "\n",
    "def _counts(input_state, l, result, strategy='brute_force'):\n",
    "    if strategy == 'qiskit':\n",
    "        n_qubits = int(np.log2(len(input_state)))\n",
    "        circuit = QuantumCircuit(n_qubits)\n",
    "        circuit.initialize(input_state)\n",
    "    else:\n",
    "        circuit = baa_schmidt(input_state, use_low_rank=True, max_fidelity_loss=l, strategy=strategy)\n",
    "    transpiled_circuit = transpile(circuit, basis_gates=['u1','u2','u3', 'cx'], optimization_level=3)\n",
    "    \n",
    "    count_ops = transpiled_circuit.count_ops()\n",
    "    n_cx = 0\n",
    "    if 'cx' in count_ops:\n",
    "        n_cx = count_ops['cx']\n",
    "    n_dp = transpiled_circuit.depth()\n",
    "\n",
    "    fidelity = _fidelity(input_state, transpiled_circuit)\n",
    "\n",
    "    result.append([l, n_cx, n_dp, fidelity])\n",
    "        \n",
    "def _grid_search(input_state, fidelity_loss=None):\n",
    "    result = []\n",
    "    if fidelity_loss is None:\n",
    "        fidelity_loss = [i/10 for i in range(7)]\n",
    "\n",
    "    n = int(np.log2(len(input_state)))\n",
    "    for l in fidelity_loss:\n",
    "        _counts(input_state, l=l, result=result, strategy='brute_force')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def _print_results(results):\n",
    "    fidelity_loss = [r[0] for r in results[0]]\n",
    "\n",
    "    n_cx = {}\n",
    "    n_dp = {}\n",
    "    fidelity = {}\n",
    "    for l in fidelity_loss:\n",
    "        n_cx[l] = []\n",
    "        n_dp[l] = []\n",
    "        fidelity[l] = []\n",
    "\n",
    "    for result in results:\n",
    "        for l in fidelity_loss:\n",
    "            n_cx[l].extend([r[1] for r in result if r[0]==l])\n",
    "            n_dp[l].extend([r[2] for r in result if r[0]==l])\n",
    "            fidelity[l].extend([r[3] for r in result if r[0]==l])\n",
    "    \n",
    "    print('AVG:')\n",
    "    for l in fidelity_loss:\n",
    "        avg_cx = sum(n_cx[l]) / len(n_cx[l])\n",
    "        avg_dp = sum(n_dp[l]) / len(n_dp[l])\n",
    "        avg_fidelity = sum(fidelity[l]) / len(fidelity[l])\n",
    "        print('l={3}\\tCNOTs={0}\\tdepth={1}\\tfidelity={2}'.format(avg_cx, avg_dp, avg_fidelity, l))\n",
    "    \n",
    "    print('STD:')\n",
    "    for l in fidelity_loss:\n",
    "        std_cx = np.std(n_cx[l])\n",
    "        std_dp = np.std(n_dp[l])\n",
    "        std_fidelity = np.std(fidelity[l])\n",
    "        print('l={3}\\tCNOTs={0}\\tdepth={1}\\tfidelity={2}'.format(std_cx, std_dp, std_fidelity, l))\n",
    "\n",
    "results = []\n",
    "for i in training_input:\n",
    "    print(i)\n",
    "    for input_state in training_input[i]:\n",
    "        results.append(_grid_search(input_state))\n",
    "print()\n",
    "for i in test_input:\n",
    "    print(i)\n",
    "    for input_state in training_input[i]:\n",
    "        results.append(_grid_search(input_state))\n",
    "\n",
    "_print_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
