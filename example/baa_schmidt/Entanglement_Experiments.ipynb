{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from test.test_baa import execute_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_qubits = 7\n",
    "entanglement_bounds = (0.4, 1.0)\n",
    "max_fidelity_loss = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "data = [(i, num_qubits, entanglement_bounds, max_fidelity_loss, False, [1, 5]) for i in range(100)]\n",
    "if use_parallel:\n",
    "    with Pool() as pool:\n",
    "        result = pool.starmap(execute_experiment, data)\n",
    "else:\n",
    "    result = [execute_experiment(*d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>with_low_rank</th>\n",
       "      <th>strategy</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>depth</th>\n",
       "      <th>cnots</th>\n",
       "      <th>entganglement</th>\n",
       "      <th>entganglement (MW)</th>\n",
       "      <th>max_fidelity_loss</th>\n",
       "      <th>total_saved_cnots</th>\n",
       "      <th>total_fidelity_loss</th>\n",
       "      <th>data</th>\n",
       "      <th>real_cnots</th>\n",
       "      <th>real_cnots_no_approx</th>\n",
       "      <th>real_depth</th>\n",
       "      <th>real_depth_no_approx</th>\n",
       "      <th>real_fidelity_loss</th>\n",
       "      <th>real_fidelity_loss_benchmark</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>brute_force</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>[(0, [64]), (1, [2])]</td>\n",
       "      <td>54</td>\n",
       "      <td>151</td>\n",
       "      <td>89</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.390601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>greedy</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>[(0, [64]), (1, [2])]</td>\n",
       "      <td>54</td>\n",
       "      <td>151</td>\n",
       "      <td>89</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>brute_force</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.1</td>\n",
       "      <td>130</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>[(1, [2]), (2, [64])]</td>\n",
       "      <td>21</td>\n",
       "      <td>151</td>\n",
       "      <td>42</td>\n",
       "      <td>364</td>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.375066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>greedy</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.1</td>\n",
       "      <td>115</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>[(2, [128, 1])]</td>\n",
       "      <td>36</td>\n",
       "      <td>151</td>\n",
       "      <td>98</td>\n",
       "      <td>364</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.749987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>brute_force</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>146</td>\n",
       "      <td>0.190933</td>\n",
       "      <td>[(0, [8]), (1, [2]), (0, [4]), (1, [2])]</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>17</td>\n",
       "      <td>364</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "      <td>greedy</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.628701</td>\n",
       "      <td>0.9</td>\n",
       "      <td>84</td>\n",
       "      <td>0.653879</td>\n",
       "      <td>[(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.093751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>brute_force</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.628701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.653863</td>\n",
       "      <td>[(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.100685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>greedy</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.628701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673100</td>\n",
       "      <td>[(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.109413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "      <td>brute_force</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.628701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.653889</td>\n",
       "      <td>[(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.093708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "      <td>greedy</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.628701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.653864</td>\n",
       "      <td>[(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.093789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  with_low_rank     strategy  num_qubits  depth  cnots  entganglement  \\\n",
       "0      0          False  brute_force           7     14    151       0.571017   \n",
       "1      0          False       greedy           7     14    151       0.571017   \n",
       "2      0           True  brute_force           7     14    151       0.571017   \n",
       "3      0           True       greedy           7     14    151       0.571017   \n",
       "4      0          False  brute_force           7     14    151       0.571017   \n",
       "...   ..            ...          ...         ...    ...    ...            ...   \n",
       "3995  99           True       greedy           7      7     84       0.673096   \n",
       "3996  99          False  brute_force           7      7     84       0.673096   \n",
       "3997  99          False       greedy           7      7     84       0.673096   \n",
       "3998  99           True  brute_force           7      7     84       0.673096   \n",
       "3999  99           True       greedy           7      7     84       0.673096   \n",
       "\n",
       "      entganglement (MW)  max_fidelity_loss  total_saved_cnots  \\\n",
       "0               0.611636                0.1                 96   \n",
       "1               0.611636                0.1                 96   \n",
       "2               0.611636                0.1                130   \n",
       "3               0.611636                0.1                115   \n",
       "4               0.611636                0.2                146   \n",
       "...                  ...                ...                ...   \n",
       "3995            0.628701                0.9                 84   \n",
       "3996            0.628701                1.0                 84   \n",
       "3997            0.628701                1.0                 84   \n",
       "3998            0.628701                1.0                 84   \n",
       "3999            0.628701                1.0                 84   \n",
       "\n",
       "      total_fidelity_loss                                               data  \\\n",
       "0                0.054912                              [(0, [64]), (1, [2])]   \n",
       "1                0.054912                              [(0, [64]), (1, [2])]   \n",
       "2                0.055367                              [(1, [2]), (2, [64])]   \n",
       "3                0.033907                                    [(2, [128, 1])]   \n",
       "4                0.190933           [(0, [8]), (1, [2]), (0, [4]), (1, [2])]   \n",
       "...                   ...                                                ...   \n",
       "3995             0.653879  [(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...   \n",
       "3996             0.653863  [(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...   \n",
       "3997             0.673100  [(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...   \n",
       "3998             0.653889  [(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...   \n",
       "3999             0.653864  [(1, [2, 1]), (1, [2, 1]), (1, [2, 1]), (1, [2...   \n",
       "\n",
       "      real_cnots  real_cnots_no_approx  real_depth  real_depth_no_approx  \\\n",
       "0             54                   151          89                   364   \n",
       "1             54                   151          89                   364   \n",
       "2             21                   151          42                   364   \n",
       "3             36                   151          98                   364   \n",
       "4              5                   151          17                   364   \n",
       "...          ...                   ...         ...                   ...   \n",
       "3995           0                    23           2                    68   \n",
       "3996           0                    23           2                    68   \n",
       "3997           0                    23           2                    68   \n",
       "3998           0                    23           2                    68   \n",
       "3999           0                    23           2                    68   \n",
       "\n",
       "      real_fidelity_loss  real_fidelity_loss_benchmark  duration  \n",
       "0                 0.0549                           0.0  1.390601  \n",
       "1                 0.0549                           0.0  1.453099  \n",
       "2                 0.2203                           0.0  1.375066  \n",
       "3                 0.1951                           0.0  1.749987  \n",
       "4                 0.1936                           0.0  0.701098  \n",
       "...                  ...                           ...       ...  \n",
       "3995              0.6731                          -0.0  0.093751  \n",
       "3996              0.6731                          -0.0  0.100685  \n",
       "3997              0.6539                          -0.0  0.109413  \n",
       "3998              0.6731                          -0.0  0.093708  \n",
       "3999              0.6539                          -0.0  0.093789  \n",
       "\n",
       "[4000 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(result, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tests:\n",
    "# Calculation Tests\n",
    "# The benchmark will not change the state at all, so it must be essentially zero\n",
    "df['benchmark_fidelity_loss_pass'] = np.abs(df['real_fidelity_loss_benchmark']) < 1e-6\n",
    "# The expected / predicted fidelity loss must be less or equal to the max fidelity loss\n",
    "df['approximation_calculation_pass'] = df['max_fidelity_loss'] >= df['total_fidelity_loss']\n",
    "\n",
    "# The real Tests\n",
    "# The real measured fidelity measure must be less or equal to the configured mx fidelity loss\n",
    "df['real_approximation_calculation_pass'] = df['real_fidelity_loss'] < df['max_fidelity_loss']\n",
    "# The predicted maximum CNOT gates and the no-approximation count should be within 10%\n",
    "df['cnot_prediction_calculation_pass'] = np.abs(df['real_cnots_no_approx'] - df['cnots']) < 0.1 * df['cnots']\n",
    "# The predicted CNOT gates should be within an error margin of 10%\n",
    "df['saved_cnots_calculation_pass'] = np.abs(df['cnots'] - df['total_saved_cnots'] - df['real_cnots']) <= 0.1 * (df['cnots'] - df['total_saved_cnots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "timestamp_sec = int(datetime.datetime.now().timestamp())\n",
    "df.to_pickle(f'./{timestamp_sec}.test_baa.pickle')\n",
    "df.to_csv(f'./{timestamp_sec}.test_baa.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}